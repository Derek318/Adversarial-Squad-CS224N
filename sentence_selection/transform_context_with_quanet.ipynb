{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/StephanieBrito/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/StephanieBrito/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/StephanieBrito/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/StephanieBrito/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/StephanieBrito/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/StephanieBrito/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/StephanieBrito/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout, concatenate, LSTM, Dense, concatenate, Embedding\n",
    "embed_len = 32\n",
    "vocab_size = 223788\n",
    "class QUA_Net(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(QUA_Net, self).__init__()\n",
    "        self.q_embed = Embedding(vocab_size, embed_len)\n",
    "        self.s_embed = Embedding(vocab_size, embed_len)\n",
    "        self.q_lstm = LSTM(128)\n",
    "        self.s_lstm = LSTM(128)\n",
    "        self.dropout = Dropout(0.33) #0.3\n",
    "        self.dense = Dense(64, activation='relu')\n",
    "        self.dense2 = Dense(1, activation = 'sigmoid')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        q = self.q_embed(inputs[0])\n",
    "        s = self.s_embed(inputs[1])\n",
    "        \n",
    "        q_out = self.q_lstm(q)\n",
    "\n",
    "        s_out = self.s_lstm(s)\n",
    "        \n",
    "        merge = concatenate([q_out, s_out], axis = -1)\n",
    "        drop = self.dropout(merge)\n",
    "        drop2 = self.dense(drop)\n",
    "        out = self.dense2(drop2)\n",
    "        return out\n",
    "\n",
    "model = QUA_Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ujson as json\n",
    "import json\n",
    "\n",
    "with open('word2idx.json') as f:\n",
    "    word2idx = json.load(f)\n",
    "\n",
    "idx2word = {int(v): k for k, v in word2idx.items()}\n",
    "\n",
    "with open('idx2word.json', 'w') as outfile:\n",
    "    json.dump(idx2word, outfile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1   80 5137 ...    0    0    0]\n",
      " [   1   80 5137 ...    0    0    0]\n",
      " [   1   80 5137 ...    0    0    0]\n",
      " ...\n",
      " [   1   80  449 ...    1 1307    3]\n",
      " [   1   80  449 ...    1 1307    3]\n",
      " [   1   80  449 ...    1 1307    3]]\n",
      "What is a prime number\n",
      "The uniqueness in this theorem requires excluding 1 as a prime because one can include arbitrarily many instances of 1 in any , e.g.\n",
      "[[0.4971872 ]\n",
      " [0.49897256]\n",
      " [0.49899364]\n",
      " [0.4987684 ]\n",
      " [0.49996978]\n",
      " [0.49797595]\n",
      " [0.49810866]\n",
      " [0.4971872 ]\n",
      " [0.49897256]\n",
      " [0.49899364]\n",
      " [0.4987684 ]\n",
      " [0.49996978]\n",
      " [0.49797595]\n",
      " [0.49810866]\n",
      " [0.4971872 ]\n",
      " [0.49897256]\n",
      " [0.49899364]\n",
      " [0.4987684 ]\n",
      " [0.49996978]\n",
      " [0.49797595]\n",
      " [0.49810866]\n",
      " [0.4971872 ]\n",
      " [0.49897256]\n",
      " [0.49899364]\n",
      " [0.4987684 ]\n",
      " [0.49996978]\n",
      " [0.49797595]\n",
      " [0.49810866]\n",
      " [0.4971872 ]\n",
      " [0.49897256]\n",
      " [0.49899364]\n",
      " [0.4987684 ]\n",
      " [0.49996978]\n",
      " [0.49797595]\n",
      " [0.49810866]\n",
      " [0.4971872 ]\n",
      " [0.49897256]\n",
      " [0.49899364]\n",
      " [0.4987684 ]\n",
      " [0.49996978]\n",
      " [0.49797595]\n",
      " [0.49810866]\n",
      " [0.4971872 ]\n",
      " [0.49897256]\n",
      " [0.49899364]\n",
      " [0.4987684 ]\n",
      " [0.49996978]\n",
      " [0.49797595]\n",
      " [0.49810866]\n",
      " [0.4971872 ]\n",
      " [0.49897256]\n",
      " [0.49899364]\n",
      " [0.4987684 ]\n",
      " [0.49996978]\n",
      " [0.49797595]\n",
      " [0.49810866]\n",
      " [0.4971872 ]\n",
      " [0.49897256]\n",
      " [0.49899364]\n",
      " [0.4987684 ]\n",
      " [0.49996978]\n",
      " [0.49797595]\n",
      " [0.49810866]\n",
      " [0.4971872 ]\n",
      " [0.49897256]\n",
      " [0.49899364]\n",
      " [0.4987684 ]\n",
      " [0.49996978]\n",
      " [0.49797595]\n",
      " [0.49810866]\n",
      " [0.4983317 ]\n",
      " [0.49936506]\n",
      " [0.49909636]\n",
      " [0.49802208]\n",
      " [0.49891862]\n",
      " [0.4984675 ]\n",
      " [0.49806708]\n",
      " [0.4983317 ]\n",
      " [0.49936506]\n",
      " [0.49909636]\n",
      " [0.49802208]\n",
      " [0.49891862]\n",
      " [0.4984675 ]\n",
      " [0.49806708]\n",
      " [0.4983317 ]\n",
      " [0.49936506]\n",
      " [0.49909636]\n",
      " [0.49802208]\n",
      " [0.49891862]\n",
      " [0.4984675 ]\n",
      " [0.49806708]\n",
      " [0.4983317 ]\n",
      " [0.49936506]\n",
      " [0.49909636]\n",
      " [0.49802208]\n",
      " [0.49891862]\n",
      " [0.4984675 ]\n",
      " [0.49806708]\n",
      " [0.4983317 ]\n",
      " [0.49936506]\n",
      " [0.49909636]\n",
      " [0.49802208]\n",
      " [0.49891862]\n",
      " [0.4984675 ]\n",
      " [0.49806708]\n",
      " [0.4983317 ]\n",
      " [0.49936506]\n",
      " [0.49909636]\n",
      " [0.49802208]\n",
      " [0.49891862]\n",
      " [0.4984675 ]\n",
      " [0.49806708]\n",
      " [0.4983317 ]\n",
      " [0.49936506]\n",
      " [0.49909636]\n",
      " [0.49802208]\n",
      " [0.49891862]\n",
      " [0.4984675 ]\n",
      " [0.49806708]\n",
      " [0.4983317 ]\n",
      " [0.49936506]\n",
      " [0.49909636]\n",
      " [0.49802208]\n",
      " [0.49891862]\n",
      " [0.4984675 ]\n",
      " [0.49806708]\n",
      " [0.4983317 ]\n",
      " [0.49936506]\n",
      " [0.49909636]\n",
      " [0.49802208]\n",
      " [0.49891862]\n",
      " [0.4984675 ]\n",
      " [0.49806708]\n",
      " [0.4983317 ]\n",
      " [0.49936506]\n",
      " [0.49909636]\n",
      " [0.49802208]\n",
      " [0.49891862]\n",
      " [0.4984675 ]\n",
      " [0.49806708]\n",
      " [0.49820203]\n",
      " [0.4971026 ]\n",
      " [0.49961025]\n",
      " [0.49822503]\n",
      " [0.4971026 ]\n",
      " [0.49961025]\n",
      " [0.49822503]\n",
      " [0.4971026 ]\n",
      " [0.49961025]\n",
      " [0.49822503]\n",
      " [0.4971026 ]\n",
      " [0.49961025]\n",
      " [0.49822503]\n",
      " [0.4971026 ]\n",
      " [0.49961025]\n",
      " [0.49822503]\n",
      " [0.4971026 ]\n",
      " [0.49961025]\n",
      " [0.49822503]\n",
      " [0.4971026 ]\n",
      " [0.49961025]\n",
      " [0.49822503]\n",
      " [0.4971026 ]\n",
      " [0.49961025]\n",
      " [0.49822503]\n",
      " [0.4971026 ]\n",
      " [0.49961025]\n",
      " [0.49822503]\n",
      " [0.4971026 ]\n",
      " [0.49961025]\n",
      " [0.49866498]\n",
      " [0.49786398]\n",
      " [0.49948102]\n",
      " [0.49814823]\n",
      " [0.49866438]\n",
      " [0.49786398]\n",
      " [0.49948102]\n",
      " [0.49814823]\n",
      " [0.49866438]\n",
      " [0.49786398]\n",
      " [0.49948102]\n",
      " [0.49814823]\n",
      " [0.49866438]\n",
      " [0.49786398]\n",
      " [0.49948102]\n",
      " [0.49814823]\n",
      " [0.49866438]\n",
      " [0.49786398]\n",
      " [0.49948102]\n",
      " [0.49814823]\n",
      " [0.49866438]\n",
      " [0.49786398]\n",
      " [0.49948102]\n",
      " [0.49814823]\n",
      " [0.49866438]\n",
      " [0.49786398]\n",
      " [0.49948102]\n",
      " [0.49814823]\n",
      " [0.49866438]\n",
      " [0.49786398]\n",
      " [0.49948102]\n",
      " [0.49814823]\n",
      " [0.49866438]\n",
      " [0.49786398]\n",
      " [0.49948102]\n",
      " [0.49814823]\n",
      " [0.49866438]\n",
      " [0.49786398]\n",
      " [0.49948102]\n",
      " [0.49814823]\n",
      " [0.49793112]\n",
      " [0.4987181 ]\n",
      " [0.49864405]\n",
      " [0.49815014]\n",
      " [0.49926603]\n",
      " [0.49793112]\n",
      " [0.4987181 ]\n",
      " [0.49864405]\n",
      " [0.49815014]\n",
      " [0.49926603]\n",
      " [0.49793112]\n",
      " [0.4987181 ]\n",
      " [0.49864405]\n",
      " [0.49815014]\n",
      " [0.49926603]\n",
      " [0.49793112]\n",
      " [0.4987181 ]\n",
      " [0.49864405]\n",
      " [0.49815014]\n",
      " [0.49926603]\n",
      " [0.49793112]\n",
      " [0.4987181 ]\n",
      " [0.49864405]\n",
      " [0.49815014]\n",
      " [0.49926603]\n",
      " [0.49793112]\n",
      " [0.4987181 ]\n",
      " [0.49864405]\n",
      " [0.49815014]\n",
      " [0.49926603]\n",
      " [0.49793112]\n",
      " [0.4987181 ]\n",
      " [0.49864405]\n",
      " [0.49815014]\n",
      " [0.49926603]\n",
      " [0.49793112]\n",
      " [0.4987181 ]\n",
      " [0.49864405]\n",
      " [0.49815014]\n",
      " [0.49926603]\n",
      " [0.49793112]\n",
      " [0.4987181 ]\n",
      " [0.49864405]\n",
      " [0.49815014]\n",
      " [0.49926603]\n",
      " [0.49793112]\n",
      " [0.4987181 ]\n",
      " [0.49864405]\n",
      " [0.49815014]\n",
      " [0.49926603]\n",
      " [0.4987356 ]\n",
      " [0.49816734]\n",
      " [0.49798506]\n",
      " [0.49852404]\n",
      " [0.49782097]\n",
      " [0.49821597]\n",
      " [0.4983009 ]\n",
      " [0.4987356 ]\n",
      " [0.49816734]\n",
      " [0.49798506]\n",
      " [0.49852404]\n",
      " [0.49782097]\n",
      " [0.49821597]\n",
      " [0.4983009 ]\n",
      " [0.4987356 ]\n",
      " [0.49816734]\n",
      " [0.49798506]\n",
      " [0.49852404]\n",
      " [0.49782097]\n",
      " [0.49821597]\n",
      " [0.4983009 ]\n",
      " [0.4987356 ]\n",
      " [0.49816734]\n",
      " [0.49798506]\n",
      " [0.49852404]\n",
      " [0.49782097]\n",
      " [0.49821597]\n",
      " [0.4983009 ]\n",
      " [0.4987356 ]\n",
      " [0.49816734]\n",
      " [0.49798506]\n",
      " [0.49852404]\n",
      " [0.49782097]\n",
      " [0.49821597]\n",
      " [0.4983009 ]\n",
      " [0.4987356 ]\n",
      " [0.49816734]\n",
      " [0.49798506]\n",
      " [0.49852404]\n",
      " [0.49782097]\n",
      " [0.49821597]\n",
      " [0.4983009 ]\n",
      " [0.4987356 ]\n",
      " [0.49816734]\n",
      " [0.49798506]\n",
      " [0.49852404]\n",
      " [0.49782097]\n",
      " [0.49821597]\n",
      " [0.4983009 ]\n",
      " [0.4987356 ]\n",
      " [0.49816734]\n",
      " [0.49798506]\n",
      " [0.49852404]\n",
      " [0.49782097]\n",
      " [0.49821597]\n",
      " [0.4983009 ]\n",
      " [0.4987356 ]\n",
      " [0.49816734]\n",
      " [0.49798506]\n",
      " [0.49852404]\n",
      " [0.49782097]\n",
      " [0.49821597]\n",
      " [0.4983009 ]\n",
      " [0.4987356 ]\n",
      " [0.49816734]\n",
      " [0.49798506]\n",
      " [0.49852404]\n",
      " [0.49782097]\n",
      " [0.49821597]\n",
      " [0.4983009 ]\n",
      " [0.4986823 ]\n",
      " [0.4981373 ]\n",
      " [0.4984906 ]\n",
      " [0.49851537]\n",
      " [0.4986823 ]\n",
      " [0.4981373 ]\n",
      " [0.4984906 ]\n",
      " [0.49851537]\n",
      " [0.4986823 ]\n",
      " [0.4981373 ]\n",
      " [0.4984906 ]\n",
      " [0.49851537]\n",
      " [0.4986823 ]\n",
      " [0.4981373 ]\n",
      " [0.4984906 ]\n",
      " [0.49851537]]\n"
     ]
    }
   ],
   "source": [
    "import ujson as json\n",
    "import json\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from nltk import tokenize\n",
    "\n",
    "with open('idx2word.json') as f:\n",
    "    idx2word = json.load(f)\n",
    "\n",
    "\n",
    "\n",
    "def translate_idxs(words):\n",
    "    translated = \"\"\n",
    "    for line in words:\n",
    "        for idx in line:\n",
    "            if idx == 1 or idx == 0:\n",
    "                continue\n",
    "            #print(idx2word[idx])\n",
    "            translated  += idx2word[str(idx)] + \" \"\n",
    "    return translated\n",
    "        \n",
    "\n",
    "'''\n",
    "Input:\n",
    "cw_idxs: indeces for the context paragraph. you can translate this to a sentence with indx2word\n",
    "qw_idxs: question to answer\n",
    "\n",
    "Output:\n",
    "Reduced context based on QuaNet output\n",
    "\n",
    "'''\n",
    "def transform_context(cw_idxs, qw_idxs):\n",
    "    translated_context = translate_idxs(cw_idxs)\n",
    "    context_sentences = tokenize.sent_tokenize(translated_context)\n",
    "    #translated_q = [translate_idxs(qw_idxs)] * len(context_sentences)\n",
    "    translated_q = [\"What is a prime number\"] * len(context_sentences)\n",
    "\n",
    "    one_hot_sentences = [one_hot(s, vocab_size) for s in context_sentences]\n",
    "    padded_sentences = sequence.pad_sequences(one_hot_sentences, maxlen=323)\n",
    "    \n",
    "    one_hot_qs = [one_hot(q, vocab_size) for q in translated_q]\n",
    "    padded_qs = sequence.pad_sequences(one_hot_qs, maxlen=323)\n",
    "    \n",
    "    print(translated_q[0])\n",
    "    predictions = model.predict([padded_qs, padded_sentences])\n",
    "    best_sent = np.argmax(predictions)\n",
    "    print(context_sentences[best_sent])\n",
    "    print(predictions)\n",
    "\n",
    "array = np.load(\"stephanie_ex.npy\")\n",
    "print(array)\n",
    "transform_context(array, [[1, 5,3,1, 80, 1307, 7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
